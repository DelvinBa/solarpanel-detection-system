{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install mlflow\n",
    "%pip install torch\n",
    "%pip install torchvision\n",
    "\n",
    "from time import time\n",
    "from typing import List, Dict, Any, Tuple\n",
    "\n",
    "import mlflow\n",
    "import torch\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(batch_size: int) -> Tuple[Any]:\n",
    "    # Start of load time.\n",
    "    start_time = time()\n",
    "    print(\"Loading images\")\n",
    "    # Define a transform to normalize the data\n",
    "    transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,)),\n",
    "                                ])\n",
    "\n",
    "    # Download and load the training data\n",
    "    train_dataset = datasets.MNIST('./mnistdata', download=True, train=True, transform=transform)\n",
    "    test_dataset = datasets.MNIST('./mnistdata', download=True, train=False, transform=transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "    return train_loader, test_loader, len(train_dataset), len(test_dataset), (time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTModel(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_sizes: List[int], output_size: int):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.lin1 = nn.Linear(input_size, hidden_sizes[0])\n",
    "        self.lin2 = nn.Linear(hidden_sizes[0], hidden_sizes[1])\n",
    "        self.lin3 = nn.Linear(hidden_sizes[1], output_size)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.output_activation = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.lin1(x)\n",
    "        out = self.activation(out)\n",
    "        out = self.lin2(out)\n",
    "        out = self.activation(out)\n",
    "        out = self.lin3(out)\n",
    "        out = self.output_activation(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model: MNISTModel, loader: DataLoader, params: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    start_time = time()\n",
    "    loss_func = nn.NLLLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=params['lr'], momentum=params['momentum'])\n",
    "    training_metrics = {}\n",
    "    for epoch in range(params['epochs']):\n",
    "        total_loss = 0\n",
    "        for images, labels in loader:\n",
    "            # Flatten MNIST images into a 784 long vector.\n",
    "            images = images.view(images.shape[0], -1)\n",
    "        \n",
    "            # Training pass\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model(images)\n",
    "            loss = loss_func(output, labels)\n",
    "            \n",
    "            # This is where the model learns by backpropagating\n",
    "            loss.backward()\n",
    "            \n",
    "            # And optimizes its weights here\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            mlflow.log_metric('training_loss', total_loss/len(loader), epoch+1)\n",
    "            print(\"Epoch {} - Training loss: {}\".format(epoch+1, total_loss/len(loader)))\n",
    "\n",
    "    training_time_sec = (time()-start_time)\n",
    "    training_metrics['training_time_sec'] = training_time_sec\n",
    "    print(\"\\nTraining Time (in seconds) =\",training_time_sec)\n",
    "    return training_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model: MNISTModel, loader: DataLoader) -> Dict[str, Any]:\n",
    "    correct_count, total_count = 0, 0\n",
    "    for images,labels in loader:\n",
    "        for i in range(len(labels)):\n",
    "            img = images[i].view(1, 784)\n",
    "            # Turn off gradients to speed up this part\n",
    "            with torch.no_grad():\n",
    "                logps = model(img)\n",
    "\n",
    "            # Output of the network are log-probabilities, need to take exponential for probabilities\n",
    "            ps = torch.exp(logps)\n",
    "            probab = list(ps.numpy()[0])\n",
    "            pred_label = probab.index(max(probab))\n",
    "            true_label = labels.numpy()[i]\n",
    "            if(true_label == pred_label):\n",
    "                correct_count += 1\n",
    "            total_count += 1\n",
    "    \n",
    "    testing_metrics = {\n",
    "        'incorrect_count': total_count-correct_count,\n",
    "        'correct_count': correct_count,\n",
    "        'accuracy': (correct_count/total_count)\n",
    "    }\n",
    "    print(\"Number Of Images Tested =\", total_count)\n",
    "    print(\"\\nModel Accuracy =\", (correct_count/total_count))\n",
    "    return testing_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup parameters\n",
    "params = {\n",
    "    'batch_size': 64,\n",
    "    'epochs': 5,\n",
    "    'input_size': 784,\n",
    "    'hidden_sizes': [128, 64],\n",
    "    'lr': 0.035,\n",
    "    'momentum': 0.5,\n",
    "    'output_size': 10\n",
    "    }\n",
    "\n",
    "# Setup mlflow to point to our server.\n",
    "run_name = f'Learning rate={params[\"lr\"]}'\n",
    "mlflow.set_tracking_uri('http://localhost:5000/')\n",
    "mlflow.set_experiment('MNIST 3-layer network2')\n",
    "mlflow.start_run(run_name=run_name)\n",
    "\n",
    "# Log parameters\n",
    "mlflow.log_params(params)\n",
    "\n",
    "# Load the data and log loading metrics.\n",
    "train_loader, test_loader, train_size, test_size, load_time_sec = load_images(params['batch_size'])\n",
    "mlflow.log_metric('train_size', train_size)\n",
    "mlflow.log_metric('test_size', test_size)\n",
    "mlflow.log_metric('load_time_sec', load_time_sec)\n",
    "\n",
    "# Train the model and log training metrics.\n",
    "model = MNISTModel(params['input_size'], params['hidden_sizes'], params['output_size'])\n",
    "training_metrics = train_model(model, train_loader, params)\n",
    "mlflow.log_metrics(training_metrics)\n",
    "\n",
    "# Test the model and log the accuracy as a metric.\n",
    "testing_metrics = test_model(model, test_loader)\n",
    "mlflow.log_metrics(testing_metrics)\n",
    "\n",
    "# Log the raw data and the trained model as artifacts.\n",
    "mlflow.log_artifacts('./mnistdata', artifact_path='mnistdata')\n",
    "mlflow.pytorch.log_model(model, artifact_path='mnistmodel')\n",
    "\n",
    "# End the run\n",
    "mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
