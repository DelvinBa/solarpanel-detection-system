---
title: "Technical Design"
author:
  - Navid Gharapanjeh
  - Delvin Bacho
date: "2025-02-07"
toc: true
format:
    html: 
        code-fold: true
    pdf:
        geometry: 
        - top=30mm
        - left=20mm
---


# 1. Introduction 
This document is about the technical part of this solar detection project. What this project is about and what the goals and requirements are, is described extensively in the  [functional design](functional_design.qmd).
The technical design is documented using the arc42 template and will tailor it for this project if needed. The architectural diagrams should be in c4/mermaid. If you are currently reading this on pdf, you can switch to our [hosted web-version](https://02-7e9b18.gitlab.io/docs/technical_functional_design/technical_design.html) for better readibility. 


# 2. Constraints
- **Technical constraints**: 
  - Hardware, software and cloud providers should be free or open source
  - Cloud providers: Either Cloud Student Accounts (e.g. Azure or AWS) or Saxions AWS Account
  - Our own machine is not ideal, since we train on images (limited computing power if we have no computation server)
- **Operational constraints**: 
  - Deadline: 20. April 2025
  - Personell: Group of two software engineers/computer scientists, with limited knowledge in DataScience/ML
  - We have the Training data given by the project, which is publicly available. However the Inference data, is not available, and needs to be scraped by us. Training Data (houses of south germany) and Inference data (houses of netherlands), will therefore be not of the same format and region.

# 3. System Scope and Context


This section provides an **overview of the system landscape** by illustrating **who interacts with our system and how it fits into its environment**. It consists of two context diagrams:

1. **Solar Panel Detection System**  
   - Shows the primary users and external systems that interact with our Solar Panel Detection System.


## 3.1 Context Diagrams

### Solar Panel Detection System - Context Diagram  
![Context Diagram - Solarpanel Detection System](images/c4_context_diagram.svg)

The **Solar Panel Detection System** is responsible for **analyzing house images to detect solar panels**. It includes a lightweight internal data ingestion process (implemented via simple Python scripts) that fetches aerial images of Dutch houses from public services.

The main stakeholders and external systems involved are:

**Users:**
- **Developers**: Upload training images and manage the retraining process.
- **Nijhuis Bouw (Client)**: Uploads inference images and checks detection results.
- **Selin (Product Owner)**: Also uploads inference images and verifies detection results.

**External Systems:**
- **CommonDataFactory**: External service that receives a **city name** and returns a **list of addresses**.
- **Bag Viewer Kadaster**: Receives an **address** and returns **X, Y coordinates**.
- **PDOK Luchtfoto WMS**: Receives **X, Y coordinates** and returns the corresponding **aerial image** of the house.
- **Data Storage for Results**: This is an existing Excel file from Selin, where detection results are stored alongside other project-related data (e.g., for energy label calculation). A migration to a proper database is being considered.




# 4. Solution Strategy

The **main goal** of this project is to build a **fully automated, monolithic Data and ML Pipeline** that detects solar panels in aerial or satellite images and links these detections to Dutch house IDs. We adopt a **simplified machine learning pipeline**—as illustrated below—focusing on the following stages:

1. **Data Ingestion / Versioning**  
2. **Data Preprocessing**  
3. **Model Training**  
4. **Model Deployment**  
5. **Model Validation**  
6. **Model Feedback**

In general we need to distinguish between multiple big processes we will build here. 

1. Training Pipeline
This process is mostly about the above image/pipeline.
2. Dutch houses scraping process
This is what we called Webscraping System in chapter 3 System Scope and Context. This could be also seen as a part of Data ingestion 
3. Inference Pipeline

> **Note:** The pipeline diagram is adapted from the *DataOps Specialization (2024-2025), Deployment and Operations* lecture materials by Deepak Tunuguntla and Pieter Zeilstra (Saxion University of Applied Sciences).  
> For this project, **Data Validation**, **Model Tuning** and **Model Analysis** are **out of scope**.

![ML Pipeline](images/ml-pipeline.png)

Because our resources are limited and the team is small, a **monolithic end-to-end pipeline** is simpler to maintain than multiple microservices. We will still keep each phase (Ingestion, Preprocessing, Training, etc.) **modular** within the monolithic structure, so we can evolve individual steps if needed.

- **Automation & Reproducibility**: We plan to automate pipeline execution using a scheduling or orchestration mechanism (e.g., Apache Airflow).  
- **Accuracy & Domain Adaptation**: We will compare multiple Machine Learning object detection models (e.g., YOLO, Faster R-CNN). Although model tuning is out of scope, we aim to ensure a robust baseline accuracy given our training data (Germany) differs from inference data (Netherlands).  
- **House ID Linking**: A subsystem (still part of the monolith) will handle address lookups via Kadaster/PDOK APIs, linking detection results to the specific records in the existing data storage from the Selin, where more information about the same house are stored.

---

## 4.1 Addressing Key Business Goals

| **Business Goal**                                     | **Scenario**                                                                                                                                                                 | **Solution Approach**                                                                                                                                                 |
|--------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Goal 1: Automation of Solarpanel Detection System**  | - New aerial/satellite images should trigger the pipeline automatically. <br/> - Minimal manual intervention once data arrives.                                             | - **Monolithic end-to-end pipeline** with automated scheduling/orchestration. <br/> - **Containerized steps** (if applicable) to ensure consistent environments. <br/> - **Version control** for reproducibility. |
| **Goal 2: Solar Panel Detection Accuracy**             | - Model must reliably detect panels in Dutch aerial imagery. <br/> - Compare different object detection frameworks for baseline accuracy.                                    | - **Evaluate multiple ML models** (e.g., YOLO, Faster R-CNN).                |
| **Goal 3: House ID Detection / Kadaster Integration**  | - After detecting solar panels, link results to specific addresses in the final data storage                             | <br/> - **Coordinate-based matching** of bounding boxes to house polygons. <br/> - **Automated data retrieval** via public APIs and Webservices.                |




## 4.2 Technology Selection and Rationale


## Overview  
In this project, we are building an **object detection pipeline** using **YOLOv8** to analyze satellite images of houses and detect solar panels. The pipeline is designed to be **scalable, automated, and efficient**, leveraging **Apache Airflow** for orchestration, **MinIO** as the storage backend, and **PostgreSQL** as the database. Since the focus is on model training and inference, **ETL/ELT and data cleaning are not yet included**, but these may be added in the future for data transformation and preprocessing.  

## Workflow Structure  
- **MinIO** acts as an **object storage system** to store raw images and model outputs.  
- **Apache Airflow** is used to **orchestrate** the workflow, triggering model training and inference jobs.  
- **MLflow** is used for experiment **tracking, model versioning**, and logging performance metrics to ensure reproducibility and model management.
- **YOLOv8** is the chosen object detection model for identifying solar panels on roofs.  
- **PostgreSQL** is the database for storing metadata, job statuses, and model performance metrics.  

Each of these components was carefully selected based on **scalability, ease of integration, and performance**. The table below provides a comparison of the chosen tools and their alternatives.  


### Selected Components and Alternatives Comparison

| **Component**       | **Chosen Tool**   | **Why Chosen?**                                                                                                                                                    | **Alternative(s)**        | **Why Not Chosen?**                                                                                                                                  |
|--------------------|-----------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------|
| **Storage**       | **MinIO**        | - S3-compatible API, making migration and integration easier  <br> - Lightweight and can be self-hosted on-premises or in the cloud  <br> - Scalable and performant for large datasets  <br> - Open-source and cost-effective compared to managed solutions | AWS S3, Azure Blob, GCS | - Managed cloud services can be expensive for large-scale storage  <br> - Vendor lock-in concerns  <br> - Less flexibility in self-hosted environments |
| **Orchestration** | **Apache Airflow** | - Industry-standard tool for workflow orchestration  <br> - Scalable, supports distributed execution  <br> - Large community and extensive plugin support  <br> - Integrates well with MinIO, Python, and ML pipelines | Prefect, Dagster, Kubeflow | - **Prefect** is easier to use but lacks some enterprise-level capabilities like complex DAGs  <br> - **Dagster** is great for data pipelines but less mature for ML workflows  <br> - **Kubeflow** is powerful but complex to set up and maintain |
| **Model Training** | **YOLOv8**       | - State-of-the-art real-time object detection  <br> - Pre-trained models available, reducing training time  <br> - Optimized for edge and cloud deployment  <br> - Faster inference compared to alternatives, making it suitable for real-time applications | Detectron2, MMDetection, EfficientDet | - **Detectron2** allows more customization but has a steeper learning curve  <br> - **MMDetection** is powerful but requires extensive configuration  <br> - **EfficientDet** provides better accuracy but is slower for real-time object detection |
| **Database** | **PostgreSQL** | - Perfect integration with Airflow (Airflow's native metadata DB)  <br> - PostGIS extension for geospatial data (crucial for property location analysis)  <br> - Strong data integrity with ACID compliance  <br> - Open-source with no licensing costs  <br> - JSON support for flexible schema when needed  <br> - Scalable for both logging and analytical queries | SQL Server, MongoDB, TimescaleDB | - **SQL Server** has licensing costs and higher resource requirements  <br> - **MongoDB** has weaker integration with Airflow and less mature spatial capabilities  <br> - **TimescaleDB** is specialized for time-series data which is only one aspect of our needs |



# 5. Building Block View

This section outlines the overall structure of the Solar Panel Detection System, showing the main containers and their interactions. The external storage for results can optionally be integrated into the PostgreSQL database if desired.

## 5.1 Container Diagram

![Container Diagram - Solarpanel Detection System](images/c4_container_diagram.svg)

The diagram above shows the internal structure of the Solar Panel Detection System and how it interacts with external systems and users:

- **Airflow** orchestrates the entire pipeline by scheduling scraping, training, and inference tasks.
- **Solardetection Service** performs data collection (addresses, imagery), model training, and batch inference. It acts as the core logic of the system.
- **Solardetection API (FastAPI)** provides real-time detection by accepting uploaded images and returning predictions. It loads the latest trained model artifacts (from MinIO) and may reuse inference logic from the pipeline.
- **MLflow** is used by the pipeline to log experiments, including parameters, metrics, and models. It stores metadata in **PostgreSQL**.
- **PostgreSQL** serves as a central relational database for both MLflow metadata and detection results. It is written to by both the pipeline and MLflow.
- **MinIO** serves as an object storage system. The pipeline stores input images and trained model artifacts here. FastAPI retrieves model artifacts from MinIO for real-time predictions.

### External Systems

- **CommonDataFactory** provides addresses for a given city.
- **Bag Viewer Kadaster** resolves addresses to geographic coordinates.
- **PDOK** returns aerial images for given coordinates.
- **Data Storage for Results (CSV)** is an external file where final batch detection results are exported. It contains additional house-level energy data and may be merged into the PostgreSQL database in the future.
- **Nijhuis Bouw** is the external user who uploads house images and retrieves detection results via the API.




## 5.2 Component Diagrams

In this section we will look more deeply into the solarpanel detection service container, the mlflow, airflow. There other ones are not important to look into. 


### 5.2.1 Solarpanel detection service Container

Below you can see the component diagram of the solarpanel detection container. We removed all the text for the relations, because it would lead to too an unclear overview.

In general we have three components, which can be seen as three pipelines or processes. 
1. Training Pipeline

2. Inference Pipeline
3. Webscraping Process



![Component Diagram - Solarpanel Detection Container](images/c4_component_solardetection.svg)


### 5.2.2 MlFlow Container


### 5.2.3 Airflow Container

The Airflow website provides a detailed component diagram of Airflow: [https://airflow.apache.org/docs/apache-airflow/2.5.3/core-concepts/overview.html](https://airflow.apache.org/docs/apache-airflow/2.5.3/core-concepts/overview.html).  
In our project, **Airflow** schedules tasks (defined in **DAGs**) to run the **Python scripts** that implement our solar panel detection logic. Specifically:

1. **DAG Files** (Directed Acyclic Graph files) define **tasks** and **dependencies**, telling Airflow *what* to run and *when*.  
2. **Workers** (spawned by the Executor) then **execute** these tasks. When a task is triggered, the Worker loads and runs our Python code, which in turn calls out to the Solar Panel Detection Service.

In other words, the DAG files serve as the **Airflow “recipe”** for orchestrating our solar panel detection scripts; the scripts themselves *live in our codebase* (deployed to the Airflow environment) and are *executed* on Airflow Workers.
![Component Diagram - Airflow Container](images/component_airflow.png)



# 6. Runtime View
- **Data flow**: How data moves through the system.
- **Model serving process**: How predictions are generated and served.
- **Monitoring & logging**: Performance tracking and debugging.

# 7. Deployment View
- **Infrastructure choices**: Cloud services, local servers.
- **CI/CD pipeline for ML models**.
- **Containerization strategy**: Docker, Kubernetes.
- **Versioning & rollback mechanisms**.

# 8. Cross-cutting Concepts

# 9. Architectural Decisions

# 11. Risks and Technical Debt
Risks:
- Training data is different format/and location than inference data => model might perform bad

technical debts:
- To reach the goal to have an automated process for webscraping inference data(dutch housing images), it is hard in the last step, to get the bounding box of exactly one house! Unclear what offset for the boundingbox to use for houses in different size​. Maybe calculated by size of house?


---

